---
id: installation
title: Быстрый старт
---

## Системные требования

1. JDK 17.
2. GNU/Linux (работа на других окружениях не проверялась).
3. Apache HBase @HBASE_VERSION@.x с поддержкой сжатия Snappy.
4. Apache Spark @SPARK_VERSION@.x для запуска запросов на кластере.  Кроме того, в прилагаемых примерах загрузка данных также производится
   из Spark-приложения, хотя это и не является обязательным условием.
5. Кластер Apache Ignite @IGNITE_VERSION@ при использовании распределенных кэшей в Ignite (опционально).
6. sbt -- для сборки проекта.

## Сборка проекта

Сборка проекта осуществляется с помощью sbt.  Некоторые команды в sbt shell:

 - compile -- компиляция проекта
 - test -- запуск юнит-тестов
 - assembly -- сборка толстых jar-ов, применяется в yupana-jdbc и yupana-examples
 - docs/docusaurusCreateSite -- генерация документации (локальный запуск вебсервера документации из bash консоли: `cd website/; yarn start;`)

## Подготовка окружения
1. Установить hbase @HBASE_VERSION@.x
2. Для нативной поддержки snappy небходимо скопировать нативные библиотеки из сборки hadoop @HADOOP_VERSION@.x в выбранную папку и 
   добавить в hbase-env.sh строки 
```
  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/native/lib
  export JAVA_LIBRARY_PATH=$JAVA_LIBRARY_PATH:/path/to/native/lib
```

## Запуск примеров

Модуль yupana-examples содержит пример использования Yupana для анализа фактов продаж. В нём реализована схема данных
из пакета yupana-schema с добавлением двух внешних связей (каталог адресов и каталог организаций). Каталог адресов
(AddressCatalog) создает связку между номером кассы и регионом и городом, где касса находится. Каталог организаций
(OrganisationCatalog) содержит информацию о типе организации (например, аптека, супермаркет, ресторан и т.п.) и её
обезличенный идентификатор. Все каталоги используют данные из внешнего источника – базы данных PostgreSQL.

Для запуска примеров необходима база данных PostgreSQL.  По умолчанию используется база данных `yupana-example` на `localhost`.
Базу необходимо создать до запуска примера и миграции:

```
CREATE DATABASE yupana_example;
CREATE USER yupana WITH ENCRYPTED PASSWORD 'yupana';
GRANT CONNECT ON DATABASE yupana_example TO yupana;
```

После создания базы можно мигрировать:

```
sbt examples/flywayMigrate
```

Для запуска миграций с альтернативным адресом сервера PostgreSQL можно использовать команду:

```
sbt -Dflyway.url=jdbc:postgresql://server:port/db_name \
    -Dflyway.user=db_user \
    examples/flywayMigrate
```

### 1. Server

Реализация сервера на базе yupana-pekko.

Запуск из sbt:

```
examples/runMain org.yupana.examples.server.Main
```

Настройки приложения в файле `yupana-examples/src/main/resources/application.conf`.  По умолчанию сервер слушает порт
`10101`.

Для подключения к серверу нужен JDBC драйвер.  Его можно собрать командой `sbt jdbc/assembly`.  Пакет с драйвером будет
сохранен в файл: `yupana/yupana-jdbc/target/scala-@SCALA_VERSION@/yupana-jdbc-assembly-{версия_проекта}-SNAPSHOT.jar`.
Для соединения с сервером с использованием Yupana JDBC нужно указать следующие параметры: 

  - URL: `jdbc:yupana://localhost:10101`
  - Class name (класс драйвера): `org.yupana.jdbc.YupanaDriver`

### 2. ETL

Приложение эмулирует добавление данных в Yupana.  Данные генерируются случайным образом.

Для запуска есть скрипт `deploy_etl.sh`. Подразумевается что Apache Spark со Scala @SCALA_VERSION@ установлен в `/opt/spark` или задана переменная
окружения `SPARK_HOME`. Перед запуском скрипта необходимо собрать толстый JAR (в sbt `examples/assembly`).

### 3. QueryRunner

Приложение для запуска запросов к Yupana на кластере Apache Spark.  Результаты выполнения запросов сохраняются в виде CSV файлов.

SQL запрос для запуска и путь для сохранения результатов задается в `query-runner-app.conf`.

Запуск осуществляется скриптом `deploy_query_runner.sh`

## Адаптация Yupana к существующему окружению

Модуль `yupana-examples` может быть использован в качестве основы для создания собственной аналитической системы.  Для этого потребуется:

1. Определить и реализовать внешние связи для доступа к существующим источникам данных.
2. Определить схему данных на основе существующей схемы.
3. Приведенная в примерах реализация сервера запросов является минимально полной, достаточно использовать схему, реализованную
   на шаге 2, в сервере.  Однако для интеграции сервера в существующую инфраструктуру, скорее всего, понадобятся некоторые
   изменения (например, чтение настроек из другого источника, использование дополнительных настроек для внешних источников и др).
4. Реализовать ETL процесс для наполнения базы данными.  Для периодического наполнения можно использовать Spark RDD, а для
   потокового -- DStream.
